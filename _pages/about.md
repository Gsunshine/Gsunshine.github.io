---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I'm an incoming CS Ph.D. student at [LocusLab](https://github.com/locuslab) of CMU with Prof. [Zico Kolter](https://zicokolter.com/). Previously, I was a research assistant at [ZERO Lab](https://zero-lab-pku.github.io/), School of AI, Peking University, working with Prof. [Zhouchen Lin](https://zhouchenlin.github.io/).

Research
---------

I have eclectic interests in machine learning and deep learning, especially the dynamics in deep learning and the dynamics of deep learning. I believe that structured decomposition, i.e., disentanglement, is a key to understanding the emergence of intelligence, while it can be elegantly formulated and achieved by the dynamics.

- For the dynamics in deep learning, I study differentiable programming, nested optimization, and implicit models as the construction principle in neural networks.
  - This is the "forward" pass.
- For the dynamics of deep learning, I try to understand the training dynamics of neural networks, especially the gradient issue when the networks are constructed by the dynamics. I am fascinated by their landscape, including but not limited to the loss landscape, Jacobian's spectral radius landscape, etc. A strong perception drives me to believe that many problems in model design can be attributed to training.
  - This is the "backward" pass.

I am also interested in developing principled learning methods for scientific problems through the dynamics.

Publications
---------

- Deep Equilibrium Optical Flow Estimation \
  Shaojie Bai\*, **Zhengyang Geng**\*, Yash Savani, J. Zico Kolter
  (\*equal contribution) \
  In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022* \
  [[BibTex](https://github.com/Gsunshine/Gsunshine.github.io/blob/master/assets/bib/deq-flow.bib)] [[PDF]()] [[Code](https://github.com/locuslab/deq-flow)]

- On Training Implicit Models \
  **Zhengyang Geng**\*, Xin-Yu Zhang\*, Shaojie Bai, Yisen Wang, Zhouchen Lin
  (\*equal contribution) \
  In *Neural Information Processing Systems (NeurIPS) 2021* \
  [[BibTex](https://github.com/Gsunshine/Gsunshine.github.io/blob/master/assets/bib/phantom_grad.bib)] [[PDF](https://arxiv.org/pdf/2111.05177.pdf)] [[Code](https://github.com/Gsunshine/phantom_grad)] [[Slides](https://github.com/Gsunshine/Gsunshine.github.io/blob/master/assets/slides/2021_NeurIPS_On_Training_Implicit_Models_slides.pdf)] [[Poster](https://github.com/Gsunshine/Gsunshine.github.io/blob/master/assets/poster/2021_NeurIPS_On_Training_Implicit_Models_poster.pdf)]

- Residual Relaxation for Multi-view Representation Learning \
  Yifei Wang, **Zhengyang Geng**, Feng Jiang, Chuming Li, Yisen Wang, Jiansheng Yang, Zhouchen Lin. \
  In *Neural Information Processing Systems (NeurIPS) 2021* \
  [[BibTex](https://github.com/Gsunshine/Gsunshine.github.io/blob/master/assets/bib/prelax.bib)] [[PDF](https://arxiv.org/pdf/2110.15348.pdf)] [Code] [[Slides](https://yifeiwang77.github.io/files/slides/NeurIPS2021_Prelax_slides.pdf)] 

- Is Attention Better Than Matrix Decomposition? \
  **Zhengyang Geng**\*, Meng-Hao Guo\*, Hongxu Chen, Xia Li, Ke Wei, Zhouchen Lin.
  (\*equal contribution) \
  In *International Conference on Learning Representations (ICLR) 2021*, **<font color='orange'>top 3%</font>**. \
  [[BibTex](https://github.com/Gsunshine/Gsunshine.github.io/blob/master/assets/bib/ham.bib)] [[PDF](https://arxiv.org/pdf/2109.04553.pdf)] [[Code](https://github.com/Gsunshine/Enjoy-Hamburger)] [Blog Series [1 (zh)](https://zhuanlan.zhihu.com/p/369769485), [2 (zh)](https://zhuanlan.zhihu.com/p/369855045), [3 (zh)](https://zhuanlan.zhihu.com/p/370410446)] [[Poster](https://github.com/Gsunshine/Gsunshine.github.io/blob/master/assets/poster/2021_ICLR_Ham_poster.png)]
  